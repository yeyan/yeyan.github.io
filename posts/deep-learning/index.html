<!DOCTYPE html>
<html lang="en" data-theme=""><head>
    <title> Ye Yan | Deep Learning with PyTorch (In Progress) </title>

    
    <meta charset="utf-8"><meta name="generator" content="Hugo 0.54.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="ML is the next eletricity">
    
    <link rel="stylesheet"
          href="https://yeyan.github.io/css/style.min.c3440f459b20b231a2e4ba0cc8d2bbf90db0ca0bcda990d9c05b805afb8b6198.css"
          integrity="sha256-w0QPRZsgsjGi5LoMyNK7&#43;Q2wygvNqZDZwFuAWvuLYZg="
          crossorigin="anonymous"
          type="text/css">
    
    <link rel="stylesheet"
        href="https://yeyan.github.io/css/markupHighlight.min.9755453ffb7bc4cd220f86ebb5922107b49f193cc62fc17e9785d27b33a8bf5b.css"
        integrity="sha256-l1VFP/t7xM0iD4brtZIhB7SfGTzGL8F&#43;l4XSezOov1s="
        crossorigin="anonymous"
        type="text/css">
    
    <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA=="
    crossorigin="anonymous" />

    
    <link rel="shortcut icon" href="https://yeyan.github.io/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="https://yeyan.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://yeyan.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://yeyan.github.io/favicon-16x16.png">

    <link rel="canonical" href="https://yeyan.github.io/posts/deep-learning/">

    
    
    
    
    <script type="text/javascript"
            src="https://yeyan.github.io/js/anatole-header.min.e782db136ec18d105a4552702eac49f4620d6867da3fbf808bd53e806c96be6e.js"
            integrity="sha256-54LbE27BjRBaRVJwLqxJ9GINaGfaP7&#43;Ai9U&#43;gGyWvm4="
            crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Deep Learning with PyTorch (In Progress)"/>
<meta name="twitter:description" content="Neural network (NN) is one of the hottest topics today. Scientists have invented lots of specialized variations of them: Long/Short Term Memory (LSTM), Gated Recurrent Unit (GRU), Deep Convolutional Network (DCN), Auto Encoder (AE) and etc. All of those are essentially different ways of constructing parametric functional approximations. In this post, I would like to introduce some basics about networks.
1. Neural Network to the Bare-Bones The simplest neural network actually has its own name: Logistic Regression."/>

</head>
<body><div class="sidebar animated fadeInDown ">
    <div class="logo-title">
        <div class="title">
            <img src="https://yeyan.github.io/img/yeyan.jpg" alt="profile picture">
            <h3 title=""><a href="/">Ye&#39;s ML Cafe</a></h3>
            <div class="description">
                <p>ML is the next eletricity</p>
            </div>
        </div>
    </div>
    <ul class="social-links">
        
            <li>
                <a href="http://github.com/yeyan" rel="me" aria-label="">
                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://www.linkedin.com/in/ye-yan-83921a154" rel="me" aria-label="">
                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
    <div class="footer">
        <div class="by_farbox">&copy; Ye Yan 2020 </div>
    </div>
</div>
<div class="main">
    <div class="page-top  animated fadeInDown ">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
    </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a 
                   href="/"
                        
                   title="">Home</a></li>
        
            
            <li><a 
                   href="/about/"
                        
                   title="">About</a></li>
        
        
        <li class="theme-switch-item">
            <a class="theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>

    <div class="autopagerize_page_element">
        <div class="content">
    <div class="post  animated fadeInDown ">
        <div class="post-content">
            <div class="post-title">
                <h3>Deep Learning with PyTorch (In Progress)</h3>
                
            </div>

            <p>Neural network (NN) is one of the hottest topics today. Scientists have invented lots of specialized variations of them: Long/Short Term Memory (LSTM), Gated Recurrent Unit (GRU), Deep Convolutional Network (DCN), Auto Encoder (AE) and etc. All of those are essentially different ways of constructing parametric functional approximations. In this post, I would like to introduce some basics about networks.</p>
<h3 id="neural-network-to-the-bare-bones">1. Neural Network to the Bare-Bones</h3>
<p>The simplest neural network actually has its own name: Logistic Regression. Assuming we have an input vector <span class="math inline">\(X\)</span> and a parametric matrix <span class="math inline">\(M\)</span>, then it can be expressed as <span class="math inline">\(\hat{Y}=\sigma(MX)\)</span> where <span class="math inline">\(\sigma\)</span> is the sigmoid function which is <span class="math inline">\(\sigma(x) = 1/(1 + e^{-x})\)</span>. A plain fully connected deep neural network can be expressed as the following:</p>
<p><span class="math display">\[
\begin{aligned}
A_0 &amp;= X
\\
A_1 &amp;= h(M_1A_0)
\\
A_2 &amp;= h(M_2A_1)
\\
A_3 &amp;= h(M_3A_2)
\\
\vdots
\\
\hat{Y} &amp;= h(M_{n}A_{n})
\end{aligned}
\]</span></p>
<p><span class="math inline">\(X\)</span> is the input, <span class="math inline">\(Y\)</span> is the output. <span class="math inline">\(h\)</span> here is a non-linear function which takes a vector as input and outputs another vector, theoretically it can be any function that is differentiable. In practice, we often pick functions like ReLU, LeakyReLU or sigmoid (Ironically, ReLU and LeakyReLU is not differentiable at 0, but we still use them as they have computation advantages). <span class="math inline">\(M_1, M_2 \dots,M_n\)</span> are parametric matrices between each layer.</p>
<h3 id="build-a-neural-network-to-recognize-hand-written-digits">2. Build a Neural Network to Recognize Hand Written Digits</h3>
<p>It is possible for one to hand make a neural network. But in practice, we often choose a mature deep learning framework to start with. Strictly speaking all those deep learning frameworks are essentially auto differentiation engines. As the raise of CUDA, all the main stream deep learning framework provide GPU based calculation, which is often a few times faster than CPU based calculation.</p>
<p>In this post, we choose PyTorch as our deep learning framework. I find PyTorch hides less than Tensorflow in API level, which make it easier when you want to use some uncanny architecture. In the rest of this post we will use PyTorch to train a neural network that can recognize MNIST hand writing digits.</p>
<h4 id="download-and-prepare-data">2.1 Download and Prepare Data</h4>
<p>MNIST data is available almost everywhere, lots of deep learning framework ships MNIST dataset as a part of the package. In this post, we will do it in the old fashion way: download MNIST from <a href="http://yann.lecun.com/exdb/mnist/">Yann LeCun’s website</a>. I have made a simple shell script to download the dataset which can be found <a href="download.sh">here</a>.</p>
<p>The data was code in IDX file format. The first 4 bytes are the magic number of the file. Depends on the dimension of the array, the consecutive bytes (4 as a chunk) indicates the shape of the array stored. The following code shows how to convert the binary file into an numpy array.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">load_data</span>(filename):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Load data from Idx file.
</span><span style="color:#e6db74">        The first 4 bytes are magic number which indicates the file type
</span><span style="color:#e6db74">        The following bytes indicates the shape of the data
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#75715e"># determine the dimensionality of the array.</span>
    match <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>search(re<span style="color:#f92672">.</span>compile(<span style="color:#e6db74">&#39;idx(?P&lt;index_size&gt;\d+)-ubyte.gz$&#39;</span>), filename)
    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> match:
        <span style="color:#66d9ef">raise</span> InvalidArgument(<span style="color:#e6db74">&#34;Not a idx byte file!&#34;</span>)

    <span style="color:#66d9ef">with</span> gzip<span style="color:#f92672">.</span>open(filename, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> fd:
        <span style="color:#75715e"># parse the shape of the array.</span>
        shape <span style="color:#f92672">=</span> [int<span style="color:#f92672">.</span>from_bytes(fd<span style="color:#f92672">.</span>read(<span style="color:#ae81ff">4</span>), <span style="color:#e6db74">&#39;big&#39;</span>) <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(int(match<span style="color:#f92672">.</span>group(<span style="color:#e6db74">&#39;index_size&#39;</span>)) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)][<span style="color:#ae81ff">1</span>:]
        <span style="color:#75715e"># load data and reshape as the file indicated.</span>
        <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>frombuffer(fd<span style="color:#f92672">.</span>read(), dtype<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>uint8)<span style="color:#f92672">.</span>reshape(shape)</code></pre></div>
<p>Load data as numpy array is not the end of the story. The pixel value is ranged from 0 to 255, feed this directly to neural network will cause the parameters of the neural network flutter up and down violently, therefore we normalize it by dividing 255. Further more, as PyTorch only operates on tensors, all the data needs to convert into tensors.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># We prefer GPU for training as it almost always means faster</span>
<span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available():
    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#39;cuda:0&#39;</span>)
<span style="color:#66d9ef">else</span>:
    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#39;cpu&#39;</span>)

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prepare</span>(x, y):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Convert numpy arrays to tensors, and also normalize images.
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#75715e"># normalize image pixels</span>
    images <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(x<span style="color:#f92672">.</span>astype(np<span style="color:#f92672">.</span>float32))
    images <span style="color:#f92672">/=</span> <span style="color:#ae81ff">255.</span>
    images <span style="color:#f92672">=</span> images<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)

    <span style="color:#75715e"># move data to GPU if available</span>
    <span style="color:#66d9ef">return</span> images<span style="color:#f92672">.</span>to(device), torch<span style="color:#f92672">.</span>from_numpy(y)<span style="color:#f92672">.</span>to(device, dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long)

<span style="color:#75715e"># Load training data.</span>
train_x, train_y <span style="color:#f92672">=</span> prepare(
  load_data(<span style="color:#e6db74">&#39;data/train-images-idx3-ubyte.gz&#39;</span>),
  load_data(<span style="color:#e6db74">&#39;data/train-labels-idx1-ubyte.gz&#39;</span>)
)

<span style="color:#75715e"># Load testing data.</span>
test_x, test_y <span style="color:#f92672">=</span> prepare(
    load_data(<span style="color:#e6db74">&#39;data/t10k-images-idx3-ubyte.gz&#39;</span>),
    load_data(<span style="color:#e6db74">&#39;data/t10k-labels-idx1-ubyte.gz&#39;</span>)
)</code></pre></div>
<p>In the above code, the planed output of neural network is in one-hot format. Theoretically, <span class="math inline">\(y\)</span> here need to be in one-hot format as well. But PyTorch provides a very convenient loss functor named <code>CrossEntropyLoss</code> which has done all those for us. Therefore, we only need to pack the ground truth label in a LongTensor.</p>
<h4 id="describe-the-neural-network-architecture-in-pytorch">2.2 Describe The Neural Network Architecture in PyTorch</h4>
<p>The following code shows a “deep” convolutional network, that reads an 28x28 grey scale hand writing digit and outputs the probabilities of being each digits (0 to 9):</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">import</span> torch
<span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn

<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Model</span>(nn<span style="color:#f92672">.</span>Module):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Convolutional neural network for MNIST dataset
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">def</span> __init__(self):
        <span style="color:#75715e"># Required for any PyTorch Module</span>
        super()<span style="color:#f92672">.</span>__init__()

        <span style="color:#75715e"># Layers</span>
        self<span style="color:#f92672">.</span>layers <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleList([
            <span style="color:#75715e"># Convolutional Layer 1</span>
            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)),
            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">32</span>),
            nn<span style="color:#f92672">.</span>ReLU(),
            nn<span style="color:#f92672">.</span>Dropout(<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>),
            nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
            <span style="color:#75715e"># Convolutional Layer 2</span>
            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span>False),
            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">64</span>),
            nn<span style="color:#f92672">.</span>ReLU(),
            nn<span style="color:#f92672">.</span>Dropout(<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>),
            nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
            <span style="color:#75715e"># Convolutional Layer 3</span>
            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span>False),
            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">128</span>),
            nn<span style="color:#f92672">.</span>ReLU(),
            nn<span style="color:#f92672">.</span>Dropout(<span style="color:#f92672">.</span><span style="color:#ae81ff">1</span>),
            nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
            <span style="color:#75715e"># Convolutional Layer 4</span>
            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span>False),
            nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">128</span>),
            nn<span style="color:#f92672">.</span>ReLU(),
            nn<span style="color:#f92672">.</span>Flatten(),
            <span style="color:#75715e"># Fully Connected layer 1</span>
            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">1152</span>, <span style="color:#ae81ff">512</span>, bias<span style="color:#f92672">=</span>False),
            nn<span style="color:#f92672">.</span>BatchNorm1d(<span style="color:#ae81ff">512</span>),
            nn<span style="color:#f92672">.</span>ReLU(),
            <span style="color:#75715e"># Fully Connected layer 2</span>
            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">256</span>, bias<span style="color:#f92672">=</span>False),
            nn<span style="color:#f92672">.</span>BatchNorm1d(<span style="color:#ae81ff">256</span>),
            nn<span style="color:#f92672">.</span>ReLU(),
            <span style="color:#75715e"># Fully Connected layer 3</span>
            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">10</span>, bias<span style="color:#f92672">=</span>False),
            nn<span style="color:#f92672">.</span>Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
        ])
        <span style="color:#75715e"># Move model to GPU if possible</span>
        self<span style="color:#f92672">.</span>to(device)

    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
        <span style="color:#75715e"># Apply each layer sequentially</span>
        <span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>layers:
            x <span style="color:#f92672">=</span> layer(x)
        <span style="color:#66d9ef">return</span> x</code></pre></div>
<p><strong>2.2.1 Convolutional Layer</strong></p>
<p><code>torch.nn.Conv2d</code> defines a convolutional layer. Convolutional layers are very common in computer vision, as they shine in capturing local features. Assuming <span class="math inline">\(X\)</span> is a 3x3 matrix which represents a channel of a image, and K is a 2x2 matrix which is a kernel/filter matrix. Then their convolution can be express as the following:</p>
<p><span class="math display">\[
\begin{aligned}
X &amp;= \begin{bmatrix}
  x_1 &amp; x_2 &amp; x_3\\
  x_4 &amp; x_5 &amp; x_6\\
  x_8 &amp; x_7 &amp; x_9\\
\end{bmatrix}
\\
K &amp;= \begin{bmatrix}
  k_1 &amp; k_2\\
  k_3 &amp; k_4\\
\end{bmatrix}
\\
Conv(X, K) &amp;= \begin{bmatrix}
  x_1k_1 + x_2k_2 + x_4k_3 + x_5k_4 &amp; x_2k_1 + x_3k_2 + x_5k_3 + x_6k_4\\
  x_4k_1 + x_5k_2 + x_8k_3 + x_7k_4 &amp; x_5k_1 + x_6k_2 + x_7k_3 + x_9k_4
\end{bmatrix}
\end{aligned}
\]</span></p>
<p>We can also illustrate the idea in plain Python:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">from</span> torch.nn <span style="color:#f92672">import</span> functional <span style="color:#66d9ef">as</span> F

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">conv_channel</span>(inputs, kernel, padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)):
    iheight, iwidth <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>shape
    pheight, pwidth <span style="color:#f92672">=</span> padding

    <span style="color:#75715e"># pad input image with zeros around border</span>
    padded_inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(iheight <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> pheight, iwidth <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> pwidth)
    padded_inputs[pheight:pheight <span style="color:#f92672">+</span> iheight, pwidth: pwidth <span style="color:#f92672">+</span> iwidth] <span style="color:#f92672">=</span> inputs

    kheight, kwidth <span style="color:#f92672">=</span> kernel<span style="color:#f92672">.</span>shape

    <span style="color:#75715e"># calculate output shape</span>
    output_shape <span style="color:#f92672">=</span> (iheight <span style="color:#f92672">-</span> kheight <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> pheight, iwidth <span style="color:#f92672">-</span> kwidth <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> pwidth)
    output_shape <span style="color:#f92672">=</span> [np<span style="color:#f92672">.</span>ceil(o <span style="color:#f92672">/</span> s)<span style="color:#f92672">.</span>astype(int) <span style="color:#66d9ef">for</span> o, s <span style="color:#f92672">in</span> zip(output_shape, stride)]

    <span style="color:#75715e"># initialize output tensor</span>
    output <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(output_shape)

    <span style="color:#66d9ef">for</span> h <span style="color:#f92672">in</span> range(output_shape[<span style="color:#ae81ff">0</span>]):
        <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> range(output_shape[<span style="color:#ae81ff">1</span>]):
            <span style="color:#75715e"># calculate with part of input image we want to filter</span>
            hi, wi <span style="color:#f92672">=</span> [d <span style="color:#f92672">*</span> s <span style="color:#66d9ef">for</span> d, s <span style="color:#f92672">in</span> zip([h, w], stride)]
            <span style="color:#75715e"># apply kernel/filter matrix to the part of the image and assign the result to output</span>
            output[h, w] <span style="color:#f92672">=</span> (kernel <span style="color:#f92672">*</span> padded_inputs[hi:hi <span style="color:#f92672">+</span> kheight, wi:wi <span style="color:#f92672">+</span> kwidth])<span style="color:#f92672">.</span>sum()

    <span style="color:#66d9ef">return</span> output

<span style="color:#75715e"># Define a single 1 channel (grey scale) 5x5 image</span>
<span style="color:#75715e"># Batch Size, Channel, Height, Width</span>
inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">5</span>)

<span style="color:#75715e"># Define a single 2x3 kernel/filter</span>
<span style="color:#75715e"># Output Channel, Input Channel, Height, Width</span>
kernel <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)

<span style="color:#75715e"># Compare conv_channel&#39;s output and PyTorch&#39;s conv2d&#39;s output</span>

padding <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>)
stride <span style="color:#f92672">=</span> (<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">3</span>)

<span style="color:#66d9ef">assert</span> torch<span style="color:#f92672">.</span>eq(
    conv_channel(inputs[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, :, :], kernel[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, :, :], padding<span style="color:#f92672">=</span>padding, stride<span style="color:#f92672">=</span>stride),
    F<span style="color:#f92672">.</span>conv2d(inputs, kernel, padding<span style="color:#f92672">=</span>padding, stride<span style="color:#f92672">=</span>stride)[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, :, :]
)<span style="color:#f92672">.</span>all()<span style="color:#f92672">.</span>item()</code></pre></div>
<p><strong>2.2.2 Batch Normalization Layer</strong></p>
<p>Batch normalization, despite has a bit regulatory effect, is mainly used to speed up training. It is very commonly found in deep networks. Assuming batch <span class="math inline">\(B\)</span> have <span class="math inline">\(n\)</span> elements, then:</p>
<p><span class="math display">\[
\begin{aligned}
B &amp;= \{x_1, x_2 \dots x_n\}\\
\mu_B &amp;= \frac{1}{n}\sum_{i=1}^n x_i\\
\sigma^2_B &amp;= \frac{1}{n} \sum_{i=1}^n (x_i - \mu_B)^2\\
\hat{x_i} &amp;= \frac{x_i - \mu_B}{\sqrt{\sigma^2 + \epsilon}}\\
B_{normalized} &amp;= \{\hat{x_1},\hat{x_2} \dots \hat{x_n}\}
\end{aligned}
\]</span></p>
<p>It can be also very easily illustrated in plain python: <div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py">inputs <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">3</span>)

<span style="color:#75715e"># Mean</span>
mu <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">3</span>)
<span style="color:#75715e"># Variance</span>
var <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">3</span>) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>

<span style="color:#75715e"># We use epsilon to prevent denominator to be zero</span>
epsilon <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-5</span>

torch<span style="color:#f92672">.</span>isclose(
    F<span style="color:#f92672">.</span>batch_norm(inputs, mu, var, eps<span style="color:#f92672">=</span>epsilon),
    (inputs <span style="color:#f92672">-</span> mu) <span style="color:#f92672">/</span> (var <span style="color:#f92672">+</span> epsilon)<span style="color:#f92672">.</span>sqrt()
)</code></pre></div></p>
<p>There is one more thing worth to notice, as after batch normalization expectation of the input is zero, we don’t have to have bias for the next adjacent layer.</p>
<p><strong>2.2.3 Dropout Layer</strong></p>
<p>Deep neural network is susceptible to over fit. It has so many parameters, which make it very vulnerable to fit into the noise in the training set. Dropout is a very computationally cheap way of regulating neural networks.</p>
<p>Dropout only takes effect while in training. Assume input <span class="math inline">\(X = \begin{bmatrix} x_1 &amp; x_2 &amp; \dots &amp; x_n \end{bmatrix}\)</span> mask array <span class="math inline">\(D = \begin{bmatrix} d_1 &amp; d_2 &amp; \dots d_n \end{bmatrix}\)</span> and <span class="math inline">\(\forall d_i \in \{1, 0\}\; i \in \{1 \dots n\}; p = 1 - \frac{1}{n}\sum_{i=1}^n d_i\)</span> where p is the dropout rate. Then dropout output <span class="math inline">\(\hat{X} = \begin{bmatrix} x_1 d_1 &amp; x_2 d_2 &amp; \dots &amp; x_n d_n\end{bmatrix}\)</span>. After training is done, we need scale down parameters with <span class="math inline">\(1 - p\)</span>, as dropout makes those coefficients a bit larger.</p>
<p>To illustrate this concept a bit intuitively, we can apply dropout on a MNIST hand writing images:</p>
<p><img src="dropout.png" /></p>
<p>We can still recognize those digits, although the last image has 40% of its feature missing. To some extent we can think dropout provides a way of breaking weak covariance between variables. Therefore, it encourages neural network to seek more reliable features, which makes our neural networks generalize better.</p>
<p><strong>2.2.4 Max Pooling Layer</strong></p>
<p>Max pooling layers have some regulatory effects by emphasising the most locally activated feature, enticing neural networks develop distinctive features.</p>
<p>Max pooling mechanism is somewhat similar to convolution. In both mechanism, we have a moving window size defined by kernel size and dilation. In convolution, what we after is the dot product between the matrix selected by moving window and kernel matrix, but in max pooling we only after the maximum value in selected window.</p>
<p>The following code illustrate the idea of max pooling with dilation:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#f92672">from</span> torch.nn <span style="color:#f92672">import</span> functional <span style="color:#66d9ef">as</span> F

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">max_pool_channel</span>(inputs, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, dilation<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, stride<span style="color:#f92672">=</span>None):
    <span style="color:#e6db74">&#34;&#34;&#34;Max pooling inputs on a single channel (matrix level max pooling)&#34;&#34;&#34;</span>

    <span style="color:#75715e"># Default stride to kernel size</span>
    stride <span style="color:#f92672">=</span> stride <span style="color:#f92672">or</span> kernel_size

    <span style="color:#75715e"># Calculate indices for pooling</span>
    x_ind <span style="color:#f92672">=</span> (torch<span style="color:#f92672">.</span>arange(kernel_size) <span style="color:#f92672">*</span> dilation)<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>repeat(<span style="color:#ae81ff">1</span>, kernel_size)<span style="color:#f92672">.</span>flatten()
    y_ind <span style="color:#f92672">=</span> (torch<span style="color:#f92672">.</span>arange(kernel_size) <span style="color:#f92672">*</span> dilation)<span style="color:#f92672">.</span>repeat(kernel_size)

    <span style="color:#75715e"># Determine result size</span>
    x_end <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> x_ind<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>
    y_end <span style="color:#f92672">=</span> inputs<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> y_ind<span style="color:#f92672">.</span>max() <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>

    <span style="color:#66d9ef">assert</span> x_end <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">and</span> y_end <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>, <span style="color:#e6db74">&#34;It does not make sense to max pooling a input smaller than kernel!&#34;</span>

    xsteps <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, x_end, stride)
    ysteps <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">0</span>, y_end, stride)

    result <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>empty(xsteps<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], ysteps<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>])

    <span style="color:#66d9ef">for</span> i, anchor_x <span style="color:#f92672">in</span> enumerate(xsteps):
        <span style="color:#66d9ef">for</span> j, anchor_y <span style="color:#f92672">in</span> enumerate(ysteps):
            <span style="color:#75715e"># perform max pooling</span>
            result[i, j] <span style="color:#f92672">=</span> inputs[anchor_x <span style="color:#f92672">+</span> x_ind, anchor_y <span style="color:#f92672">+</span> y_ind]<span style="color:#f92672">.</span>max()

    <span style="color:#66d9ef">return</span> result


inputs <span style="color:#f92672">=</span> (torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">9</span>) <span style="color:#f92672">*</span> <span style="color:#ae81ff">100</span>)<span style="color:#f92672">.</span>floor()

<span style="color:#66d9ef">assert</span> torch<span style="color:#f92672">.</span>isclose(
    max_pool_channel(inputs[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, :, :], kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, dilation<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
    F<span style="color:#f92672">.</span>max_pool2d(inputs, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, dilation<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
)</code></pre></div>
<h4 id="train-the-network">2.3 Train the Network</h4>
<p>Now we have briefly discussed the convolutional neural network (CNN) we defined. When a neural network is initialized, all its parameters are set to random numbers. This is actually crucial for a neural network, as stochastic gradient descent (SGD) like methods are dominantly used in training neural networks. Uniformly set neural network initial weights pair with SGD like training methods will impair neural network’s ability to capture different features. There are many ways of initializing the weights. Pytorch initialize weights base on the type of the layer by default, in our case it is using Xavier initialization for both convolutional layers and linear layers.</p>
<p>As I mentioned before: after all these years development, stochastic gradient descent is still the main work horse for neural network training. But we rare use pure stochastic gradient descent anymore in practice. Variants like Adagrad, RMSProp and Adam have superseded SGD. The solo problem those variant optimizers trying to resolve is that the learning rate for different parameter in different phase of training should be different to be optimal and it is tedious and if not impossible to adjust those by hands.</p>
<p>The following code shows how typically a neural network is trained with Pytorch:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-py" data-lang="py"><span style="color:#75715e"># This is a library used for tracking our training progress</span>
<span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate_model</span>(test_x, test_y, criterion, model, size<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>):
    <span style="color:#e6db74">&#34;Evaluate model with randomly sampled data points&#34;</span>
    <span style="color:#66d9ef">try</span>:
        model<span style="color:#f92672">.</span>eval()

        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
            <span style="color:#75715e"># test on samples from test set</span>
            index <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>multinomial(torch<span style="color:#f92672">.</span>arange(test_x<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>], dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>float32), <span style="color:#ae81ff">512</span>)
            <span style="color:#66d9ef">return</span> criterion(model(test_x[index, :, :, :]), test_y[index])<span style="color:#f92672">.</span>cpu()<span style="color:#f92672">.</span>numpy()

    <span style="color:#66d9ef">finally</span>:
        model<span style="color:#f92672">.</span>train()

<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(train_x, train_y, test_x, test_y, model, n_epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>):
    <span style="color:#75715e"># With DataLoader provided by pytorch we can easily seperate data into batches.</span>
    dataset <span style="color:#f92672">=</span> TensorDataset(train_x, train_y)
    loader <span style="color:#f92672">=</span> DataLoader(dataset, batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>)

    <span style="color:#75715e"># As this is a multi-categorical problem, the most suitable loss function is cross entropy</span>
    criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()

    <span style="color:#75715e"># For optimizer we choose Adam, which is a SGD variant</span>
    <span style="color:#75715e"># that employes momentment and friendly to gradients with different magnitudes</span>
    optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>)

    train_history <span style="color:#f92672">=</span> []
    test_history <span style="color:#f92672">=</span> []

    <span style="color:#66d9ef">try</span>:
        <span style="color:#75715e"># set model in training mode</span>
        model<span style="color:#f92672">.</span>train()
        <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> tqdm(range(n_epoch)):
            <span style="color:#66d9ef">for</span> xs, ys <span style="color:#f92672">in</span> loader:
                <span style="color:#75715e"># calculate predictions</span>
                yhats <span style="color:#f92672">=</span> model(xs)

                <span style="color:#75715e"># judge our prediction with loss function</span>
                loss <span style="color:#f92672">=</span> criterion(yhats, ys)

                <span style="color:#75715e"># clear out gradient left from last iteration</span>
                optimizer<span style="color:#f92672">.</span>zero_grad()

                <span style="color:#75715e"># generate gradient by back propagation</span>
                loss<span style="color:#f92672">.</span>backward()

                <span style="color:#75715e"># apply gradient * learning_rate to weights</span>
                optimizer<span style="color:#f92672">.</span>step()

            <span style="color:#75715e"># log training and testing accuracy</span>
            train_history<span style="color:#f92672">.</span>append(evaluate_model(train_x, train_y, model))
            test_history<span style="color:#f92672">.</span>append(evaluate_model(test_x, test_y, model))

        <span style="color:#66d9ef">return</span> [np<span style="color:#f92672">.</span>hstack(history) <span style="color:#66d9ef">for</span> history <span style="color:#f92672">in</span> [train_history, test_history]]

    <span style="color:#66d9ef">finally</span>:
        <span style="color:#75715e"># set model in evaluation mode</span>
        model<span style="color:#f92672">.</span>eval()</code></pre></div>
<p>Stochastic gradient descent brings down the computational cost significantly. But also it makes the training targets wandering around the lowest loss function terrain instead directly pointing to it. Therefore we are expecting the accuracy to jump up and down during the training process. The gap between training and testing, we can roughly consider those as over fit. As neural networks learned some features from training set that can not be generalized to testing sets, which means those features are actually noises. Therefore we over fit our neural network to the training set.</p>
<p><img src="loss_history.png" /></p>
<p><strong>To be continued …</strong></p>
</div>
        <div class="post-footer">
            <div class="info">
                
                <span class="separator"><a class="tag" href="/tags/deep-learning/">Deep Learning</a><a class="tag" href="/tags/computer-vision/">Computer Vision</a><a class="tag" href="/tags/pytorch/">PyTorch</a></span>

            </div>
        </div>

        
    </div>


        </div>
    </div>
</div>

<script type="text/javascript"
        src="https://yeyan.github.io/js/jquery.min.86b1e8f819ee2d9099a783e50b49dff24282545fc40773861f9126b921532e4c.js"
        integrity="sha256-hrHo&#43;BnuLZCZp4PlC0nf8kKCVF/EB3OGH5EmuSFTLkw="
        crossorigin="anonymous"></script>




<script type="text/javascript"
        src="https://yeyan.github.io/js/bundle.min.29019d55dba1c296a56403ba7d130703f0abd53dac253acbeca09ecff9a099ec.js"
        integrity="sha256-KQGdVduhwpalZAO6fRMHA/Cr1T2sJTrL7KCez/mgmew="
        crossorigin="anonymous"></script>

<script type="text/javascript"
        src="https://yeyan.github.io/js/medium-zoom.min.92f21c856129f84aeb719459b3e6ac621a3032fd7b180a18c04e1d12083f8aba.js"
        integrity="sha256-kvIchWEp&#43;ErrcZRZs&#43;asYhowMv17GAoYwE4dEgg/iro="
        crossorigin="anonymous"></script>
</body>

</html>
