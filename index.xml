<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ye&#39;s ML Cafe</title>
    <link>http://example.org/</link>
    <description>Recent content on Ye&#39;s ML Cafe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Apr 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Q Learning With Linear Approximation</title>
      <link>http://example.org/posts/q-learning-linear-approximation/</link>
      <pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/posts/q-learning-linear-approximation/</guid>
      <description>In our last post, we have used a table to track action values and built an agent that can solve randomly generated mazes. Table based \(Q(s, a)\) is pretty useful. Even in some cases that states are continuous, by discretizing states into integers we can still present action-value function with a table. In this post we are going to discuss a more general way of representing action-value function with Linear methods.</description>
    </item>
    
    <item>
      <title>Beat Mazes with Reinforcement Learning</title>
      <link>http://example.org/posts/tabular-q-learning/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/posts/tabular-q-learning/</guid>
      <description>RL is a blooming field at the moment. In my opinion, it has the most potential to become a general AI. But the main idea behind RL is actually simple and straight forward. In this blog post letâ€™s build a RL agent that can beat randomly generated mazes to demonstrate this idea.
Generate Random Maze To start, we need a maze. And honestly manually draw maze is pretty painful, therefore we are going to generate one randomly.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://example.org/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://example.org/about/</guid>
      <description>I will put something here in the future.</description>
    </item>
    
  </channel>
</rss>